{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "device = 'cuda'\n",
    "epochs = 100\n",
    "\n",
    "src_len = 8  # 源句子最大长度 encoder_input max seq len\n",
    "tgt_len = 7  # decoder_input(=output) max seq len\n",
    "\n",
    "# transformer网络参数\n",
    "d_model = 512  # Embedding Size (token embedding 和 position embedding 的编码维度)\n",
    "d_ff = 2048  # Feed Farward Dimension (512->2048->512)\n",
    "d_k = d_v = 64  # Dimension of K(=Q) and V (K和Q的维度是相同的，这里为了方便让V也等于Q)\n",
    "n_layers = 6  # Number of encoder and decoder layer blocks\n",
    "n_heads = 8  # Number of heads in Multi-Head Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "\n",
    "# 训练集\n",
    "sentences = [\n",
    "    # 中文和英语的单词个数不要求相同\n",
    "    # encoder_input           decoder_input               decoder_output\n",
    "    ['我 有 一 个 好 朋 友 P', 'S i have a good friend .', 'i have a good friend . E'],\n",
    "    ['我 有 零 个 女 朋 友 P', 'S i have zero girl friend .', 'i have zero girl friend . E']\n",
    "]\n",
    "\n",
    "# 测试集\n",
    "# 输入：”我 有 一 个 女 朋 友“\n",
    "# 输出：”i have a girlfriend“\n",
    "\n",
    "# 构建中文词表\n",
    "src_vocab = {'P': 0, '我': 1, '有': 2, '一': 3,\n",
    "             '个': 4, '好': 5, '朋': 6, '友': 7, '零': 8, '女': 9}\n",
    "src_idx2word = {i: w for i, w in enumerate(src_vocab)}\n",
    "src_vocab_size = len(src_vocab)\n",
    "\n",
    "# 构建英文词表\n",
    "tgt_vocab = {'P': 0, 'i': 1, 'have': 2, 'a': 3, 'good': 4,\n",
    "             'friend': 5, 'zero': 6, 'girl': 7, 'S': 8, 'E': 9, '.': 10}\n",
    "tgt_idx2word = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "# 构建数据\n",
    "\n",
    "\n",
    "def make_data(sentences):\n",
    "    \"\"\"把句子中的单词序列转换为单词对应词表中的索引序列\"\"\"\n",
    "    encoder_inputs, decoder_inputs, decoder_outputs = [], [], []\n",
    "    for i in range(len(sentences)):\n",
    "        encoder_input = [[src_vocab[n] for n in sentences[i][0].split()]]\n",
    "        decoder_input = [[tgt_vocab[n] for n in sentences[i][1].split()]]\n",
    "        decoder_output = [[tgt_vocab[n] for n in sentences[i][2].split()]]\n",
    "\n",
    "        encoder_inputs.extend(encoder_input)\n",
    "        decoder_inputs.extend(decoder_input)\n",
    "        decoder_outputs.extend(decoder_output)\n",
    "\n",
    "    return torch.LongTensor(encoder_inputs), torch.LongTensor(decoder_inputs), torch.LongTensor(decoder_outputs)\n",
    "\n",
    "\n",
    "encoder_inputs, decoder_inputs, decoder_outputs = make_data(sentences)\n",
    "# encoder_inputs.shape[0],encoder_inputs,decoder_inputs,decoder_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataSet(Data.Dataset):\n",
    "    \"\"\"自定义DataSet\"\"\"\n",
    "\n",
    "    def __init__(self, encoder_inputs, decoder_inputs, decoder_outputs):\n",
    "        super(SentenceDataSet, self).__init__()\n",
    "        self.encoder_inputs = encoder_inputs\n",
    "        self.decoder_inputs = decoder_inputs\n",
    "        self.decoder_outputs = decoder_outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encoder_inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoder_inputs[idx], self.decoder_inputs[idx], self.decoder_outputs[idx]\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(SentenceDataSet(\n",
    "    encoder_inputs, decoder_inputs, decoder_outputs), 2, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        i_mat = torch.pow(10000, torch.arange(0, d_model, 2) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(position / i_mat)\n",
    "        pe[:, 1::2] = torch.cos(position / i_mat)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)  # 在模型中定义一个常量pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x:[seq_len, batch_size, d_model]\"\"\"\n",
    "        x = x+self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Padding Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False,  True],\n",
      "         [False,  True],\n",
      "         [False,  True],\n",
      "         [False,  True],\n",
      "         [False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "def get_attention_padding_mask(seq_q, seq_k):\n",
    "    \"\"\"在对value向量加权和的时候, 使得padding的位置的alpha_ij=0\"\"\"\n",
    "    # 这里有两个输入是因为做cross attention时获取mask矩阵也用的这个方法，但来自enc和dec的seq长度不一定相同\n",
    "    # 这里变量中的q和k只是表示两个序列，只是个名字，和注意力中的Q、K没有关系\n",
    "    # seq_q:[batch_size, seq_len]\n",
    "    # seq_k:[batch_size, seq_len]\n",
    "\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "\n",
    "    padding_attention_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, seq_len]\n",
    "\n",
    "    # [batch_size, len_q, len_k]\n",
    "    return padding_attention_mask.expand(batch_size, len_q, len_k)\n",
    "\n",
    "seq_q = torch.Tensor([[1,2,3,0,0]])\n",
    "seq_k = torch.Tensor([[1,0]])\n",
    "\n",
    "print(get_attention_padding_mask(seq_q, seq_k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Subsequence Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attention_subsequence_mask(seq):\n",
    "    \"\"\"用于decoder_input的上三角mask\"\"\"\n",
    "    # seq:[batch_size, tgt_len]\n",
    "\n",
    "    # attn_shape:[batch_size, tgt_len, tgt_len]\n",
    "    attention_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "\n",
    "    # 返回一个上三角矩阵，第k条对角线以下元素全为0（主对角线为第0条）\n",
    "    subsequence_mask = np.triu(np.ones(attention_shape), k=1)\n",
    "\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()\n",
    "\n",
    "    return subsequence_mask\n",
    "\n",
    "seq_k = torch.Tensor([[1,2,3,4,0], [1,0,3,5,0]])\n",
    "get_attention_subsequence_mask(seq_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        说明: 在encoder-decoder的Attention层中len_q(q1,..qt)和len_k(k1,...km)可能不同\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2) / np.sqrt(d_k)) # scores:[batch_size, n_heads, len_q, len_k]\n",
    "        \n",
    "        # 使用mask矩阵填充scores(将scores中对应attn_mask为True的位置变为-1e9)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "\n",
    "        attn = nn.Softmax(dim=-1)(scores) \n",
    "\n",
    "        # attn:[batch_size, n_heads, len_q, len_k]\n",
    "        # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        context = torch.matmul(attn, V) # context: [batch_size, n_heads, len_q, d_v]\n",
    "        \n",
    "        # context：[[z1,z2,...],[...]]向量, attn为注意力稀疏矩阵（用于可视化的）\n",
    "        return context, attn\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"此类可以用于:\n",
    "    Encoder的Self-Attention\n",
    "    Decoder的Masked Self-Attention\n",
    "    Encoder-Decoder的Corss Attention\"\"\"\n",
    "    # 输入: [seq_len, d_model]\n",
    "    # 输出: [seq_len, d_model]\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)  # Q和K的维度一定是相同的，不然无法做点积\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model)\n",
    "\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        \"\"\"\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]   \n",
    "        \"\"\"\n",
    "\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "\n",
    "        # Trick: 多个head的参数矩阵是放在一起做线性变换的，然后再拆成多个head\n",
    "        #          (batch_size, seq_len, dim)\n",
    "        # -proj--> (batch_size, seq_len, dim_new)  dim_new: d_k(or d_v)\n",
    "        # -split-> (batch_size, seq_len, head, W)\n",
    "        # -trans-> (batch_size, head, seq_len, W)\n",
    "\n",
    "        # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        # K: [batch_size, n_heads, len_k, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        V = self.W_V(input_V).view(batch_size,- 1, n_heads, d_v).transpose(1, 2)\n",
    "\n",
    "        # mask矩阵也要扩充成4维\n",
    "        # attn_mask: [batch_size, seq_len, seq_len] --> [batch_size, n_heads, seq_len, seq_len]\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v]\n",
    "        # attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "\n",
    "        # 将不同head的输出向量拼接在一起\n",
    "        # context: [batch_size, n_heads, len_q, d_v] --> [batch_size, len_q, n_heads*d_v]\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)\n",
    "\n",
    "        # 保证attention的输出仍是[seq_len, d_model]\n",
    "        output = self.fc(context) # [batch_size, len_q, d_model]\n",
    "\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position-wise Feed-Forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias = False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias = False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"inputs: [batch_size, seq_len, d_model]\"\"\"\n",
    "\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual) # [batch_size, seq_len, d_model]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoderlayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoderlayer, self).__init__()\n",
    "        self.encoder_self_attn = MultiHeadAttention()\n",
    "        self.ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, encoder_inputs, encoder_self_attn_mask):\n",
    "        \"\"\"\n",
    "        encoder_inputs: [batch_size, src_len, d_model]\n",
    "        encoder_self_attn_mask: [batch_size, src_len, src_len]\n",
    "\n",
    "        encoder_outputs: [batch_size, src_len, d_model]\n",
    "        \"\"\"\n",
    "        # 3个encoder_inputs分别用于计算Q、K、V\n",
    "        encoder_outputs, attn = self.encoder_self_attn(encoder_inputs, encoder_inputs, encoder_inputs, encoder_self_attn_mask)\n",
    "        encoder_outputs = self.ffn(encoder_outputs)\n",
    "        # encoder_outputs: [batch_size, src_len, d_model]\n",
    "        return encoder_outputs, attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.decoder_self_attn = MultiHeadAttention()\n",
    "        self.decoder_encoder_att = MultiHeadAttention()\n",
    "        self.ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, decoder_inputs, encoder_outputs, decoder_self_attn_mask, decoder_encoder_attn_mask):\n",
    "        \"\"\"\n",
    "        decoder_inputs:[batch_size, tgt_len, d_model]\n",
    "        encoder_outputs:[batch_size, src_len, d_model]\n",
    "        decoder_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        decoder_encoder_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        \"\"\"\n",
    "        # decoder_outputs: [batch_size, tgt_len, d_model]\n",
    "        # decoder_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        decoder_outputs, decoder_self_attn = self.decoder_self_attn(decoder_inputs, decoder_inputs, decoder_inputs, decoder_self_attn_mask)\n",
    "        # decoder_encoder_attn: [batch_size, n_heads, tgt_len, src_len]\n",
    "        decoder_outputs, decoder_encoder_attn = self.decoder_encoder_att(decoder_inputs, encoder_outputs, encoder_outputs, decoder_encoder_attn_mask)\n",
    "        decoder_outputs = self.ffn(decoder_outputs)\n",
    "\n",
    "        return decoder_outputs, decoder_self_attn, decoder_encoder_attn # 后两个是用于可视化的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([Encoderlayer() for _ in range (n_layers)])\n",
    "    \n",
    "    def forward(self, encoder_inputs):\n",
    "        \"\"\"encoder_inputs: [batch_size, src_len]\"\"\"\n",
    "        encoder_outputs = self.src_emb(encoder_inputs) # [batch_size, src_len, d_model]\n",
    "        encoder_outputs = self.pos_emb(encoder_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "        # Encoder输入序列的padding mask矩阵\n",
    "        encoder_self_attn_mask = get_attention_padding_mask(encoder_inputs, encoder_inputs) # [batch_size, src_len, src_len]\n",
    "        encoder_self_attns = [] # 保存attention值画热力图用\n",
    "        for layer in self.layers:\n",
    "            encoder_outputs, encoder_self_attn = layer(encoder_outputs, encoder_self_attn_mask)\n",
    "            encoder_self_attns.append(encoder_self_attn) # 只是用于可视化\n",
    "        return encoder_outputs, encoder_self_attns\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self, decoder_inputs, encoder_inputs, encoder_outputs):\n",
    "        \"\"\"\n",
    "        decoder_inputs:[batch_size, tgt_len]\n",
    "        encoder_inputs:[batch_size, src_len]\n",
    "        encoder_outputs:[batch_size, src_len, d_model]\n",
    "        \"\"\"\n",
    "        decoder_outputs = self.tgt_emb(decoder_inputs)\n",
    "        decoder_outputs = self.pos_emb(decoder_outputs.transpose(0, 1)).transpose(0, 1).to(device) # [batch_size, tgt_len, d_model]\n",
    "        \n",
    "        # Decoder输入序列时的padding mask矩阵（这里例子中的decoder没有加pad，输入的句子长度刚好就是最大长度，但实际应用中都是需要加pad填充的）\n",
    "        decoder_self_attn_pad_mask = get_attention_padding_mask(decoder_inputs, decoder_inputs).to(device) # [batch_size, tgt_len, tgt_len]\n",
    "\n",
    "        # Masked Self-Attention\n",
    "        decoder_self_attn_subsequence_mask = get_attention_subsequence_mask(decoder_inputs).to(device) # [batch_size, tgt_len, tgt_len]\n",
    "        \n",
    "        # 把两个mask矩阵相加，既屏蔽了padding信息，又屏蔽了未来时刻的信息\n",
    "        # torch.gt用于逐元素比较两个矩阵，大于返回1，否则返回0\n",
    "        decoder_self_attn_mask = torch.gt((decoder_self_attn_pad_mask+decoder_self_attn_subsequence_mask),0).to(device)\n",
    "\n",
    "        # 用于Cross Attention的mask\n",
    "        decoder_encoder_attn_mask = get_attention_padding_mask(decoder_inputs, encoder_inputs) # [batch_size, tgt_len, src_len]\n",
    "\n",
    "        decoder_self_attns, decoder_encoder_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            decoder_outputs, decoder_self_attn, decoder_encoder_attn = layer(decoder_outputs, encoder_outputs, decoder_self_attn_mask, decoder_encoder_attn_mask)\n",
    "\n",
    "            decoder_self_attns.append(decoder_self_attn)\n",
    "            decoder_encoder_attns.append(decoder_encoder_attn)\n",
    "        \n",
    "        # decoder_outputs: [batch_size, tgt_len, d_model]\n",
    "        return decoder_outputs, decoder_self_attns, decoder_encoder_attns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False).to(device)\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        \"\"\"\n",
    "           encoder_inputs: [batch_size, src_len]\n",
    "           decoder_inputs: [batch_size, tgt_len]\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_outputs, encoder_self_attns = self.encoder(encoder_inputs)\n",
    "\n",
    "        decoder_outputs, decoder_self_attns, decoder_encoder_attns = self.decoder(decoder_inputs, encoder_inputs, encoder_outputs)\n",
    "        # decoder_outputs:[batch_size, tgt_len, d_model] --> decoder_logits:[batch_size, tgt_len, tgt_vocab_size]\n",
    "        decoder_logits = self.projection(decoder_outputs)\n",
    "\n",
    "        return decoder_logits.view(-1, decoder_logits.size(-1)), encoder_self_attns, decoder_self_attns, decoder_encoder_attns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 2.740895\n",
      "Epoch: 0002 loss= 2.635435\n",
      "Epoch: 0003 loss= 2.333206\n",
      "Epoch: 0004 loss= 2.167202\n",
      "Epoch: 0005 loss= 1.812859\n",
      "Epoch: 0006 loss= 1.651775\n",
      "Epoch: 0007 loss= 1.395540\n",
      "Epoch: 0008 loss= 1.116695\n",
      "Epoch: 0009 loss= 0.933818\n",
      "Epoch: 0010 loss= 0.772003\n",
      "Epoch: 0011 loss= 0.602071\n",
      "Epoch: 0012 loss= 0.445967\n",
      "Epoch: 0013 loss= 0.345385\n",
      "Epoch: 0014 loss= 0.240165\n",
      "Epoch: 0015 loss= 0.176040\n",
      "Epoch: 0016 loss= 0.134159\n",
      "Epoch: 0017 loss= 0.117009\n",
      "Epoch: 0018 loss= 0.087560\n",
      "Epoch: 0019 loss= 0.095686\n",
      "Epoch: 0020 loss= 0.093119\n",
      "Epoch: 0021 loss= 0.090021\n",
      "Epoch: 0022 loss= 0.087446\n",
      "Epoch: 0023 loss= 0.073897\n",
      "Epoch: 0024 loss= 0.081835\n",
      "Epoch: 0025 loss= 0.066849\n",
      "Epoch: 0026 loss= 0.059229\n",
      "Epoch: 0027 loss= 0.056727\n",
      "Epoch: 0028 loss= 0.054261\n",
      "Epoch: 0029 loss= 0.056589\n",
      "Epoch: 0030 loss= 0.045825\n",
      "Epoch: 0031 loss= 0.045650\n",
      "Epoch: 0032 loss= 0.055623\n",
      "Epoch: 0033 loss= 0.055970\n",
      "Epoch: 0034 loss= 0.058349\n",
      "Epoch: 0035 loss= 0.066749\n",
      "Epoch: 0036 loss= 0.058795\n",
      "Epoch: 0037 loss= 0.038042\n",
      "Epoch: 0038 loss= 0.037656\n",
      "Epoch: 0039 loss= 0.030715\n",
      "Epoch: 0040 loss= 0.026732\n",
      "Epoch: 0041 loss= 0.026995\n",
      "Epoch: 0042 loss= 0.026768\n",
      "Epoch: 0043 loss= 0.031500\n",
      "Epoch: 0044 loss= 0.027097\n",
      "Epoch: 0045 loss= 0.029191\n",
      "Epoch: 0046 loss= 0.035958\n",
      "Epoch: 0047 loss= 0.030653\n",
      "Epoch: 0048 loss= 0.030773\n",
      "Epoch: 0049 loss= 0.018185\n",
      "Epoch: 0050 loss= 0.012712\n",
      "Epoch: 0051 loss= 0.020805\n",
      "Epoch: 0052 loss= 0.014855\n",
      "Epoch: 0053 loss= 0.010076\n",
      "Epoch: 0054 loss= 0.009755\n",
      "Epoch: 0055 loss= 0.007729\n",
      "Epoch: 0056 loss= 0.006860\n",
      "Epoch: 0057 loss= 0.005916\n",
      "Epoch: 0058 loss= 0.006085\n",
      "Epoch: 0059 loss= 0.008200\n",
      "Epoch: 0060 loss= 0.005131\n",
      "Epoch: 0061 loss= 0.005858\n",
      "Epoch: 0062 loss= 0.006391\n",
      "Epoch: 0063 loss= 0.006318\n",
      "Epoch: 0064 loss= 0.005371\n",
      "Epoch: 0065 loss= 0.012284\n",
      "Epoch: 0066 loss= 0.005693\n",
      "Epoch: 0067 loss= 0.005539\n",
      "Epoch: 0068 loss= 0.006390\n",
      "Epoch: 0069 loss= 0.004638\n",
      "Epoch: 0070 loss= 0.004575\n",
      "Epoch: 0071 loss= 0.002671\n",
      "Epoch: 0072 loss= 0.003203\n",
      "Epoch: 0073 loss= 0.002207\n",
      "Epoch: 0074 loss= 0.001398\n",
      "Epoch: 0075 loss= 0.002311\n",
      "Epoch: 0076 loss= 0.001272\n",
      "Epoch: 0077 loss= 0.000716\n",
      "Epoch: 0078 loss= 0.000510\n",
      "Epoch: 0079 loss= 0.000346\n",
      "Epoch: 0080 loss= 0.000235\n",
      "Epoch: 0081 loss= 0.000285\n",
      "Epoch: 0082 loss= 0.000185\n",
      "Epoch: 0083 loss= 0.000143\n",
      "Epoch: 0084 loss= 0.000127\n",
      "Epoch: 0085 loss= 0.000105\n",
      "Epoch: 0086 loss= 0.000083\n",
      "Epoch: 0087 loss= 0.000062\n",
      "Epoch: 0088 loss= 0.000053\n",
      "Epoch: 0089 loss= 0.000056\n",
      "Epoch: 0090 loss= 0.000051\n",
      "Epoch: 0091 loss= 0.000051\n",
      "Epoch: 0092 loss= 0.000042\n",
      "Epoch: 0093 loss= 0.000056\n",
      "Epoch: 0094 loss= 0.000069\n",
      "Epoch: 0095 loss= 0.000048\n",
      "Epoch: 0096 loss= 0.000036\n",
      "Epoch: 0097 loss= 0.000038\n",
      "Epoch: 0098 loss= 0.000047\n",
      "Epoch: 0099 loss= 0.000055\n",
      "Epoch: 0100 loss= 0.000036\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_outputs in loader:\n",
    "        \n",
    "        # encoder_inputs: [batch_size, src_len]\n",
    "        # decoder_inputs: [batch_size, tgt_len]\n",
    "        # decoder_outputs: [batch_size, tgt_len]\n",
    "        \n",
    "        encoder_inputs, decoder_inputs, decoder_outputs = encoder_inputs.to(device), decoder_inputs.to(device), decoder_outputs.to(device)\n",
    "\n",
    "        # outputs: [batch_size*tgt_len, tgt_vocab_size]\n",
    "\n",
    "        outputs, encoder_self_attns, decoder_self_attns, decoder_encoder_attns = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        # decoder_outputs.view(-1): [batch_size * tgt_len * tgt_vocab_size]\n",
    "        loss = loss_fn(outputs, decoder_outputs.view(-1))\n",
    "\n",
    "        print('Epoch:', '%04d'%(epoch+1), 'loss=','{:.6f}'.format(loss))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoder(model, encoder_input, start_symbol):\n",
    "\n",
    "    encoder_outputs, encoder_self_attns = model.encoder(encoder_input)\n",
    "    decoder_input = torch.zeros(1, 0).type_as(encoder_input.data)\n",
    "    terminal = False\n",
    "    next_symbol = start_symbol\n",
    "    while not terminal:\n",
    "        decoder_input = torch.cat([decoder_input.to(device), torch.tensor([[next_symbol]], dtype=encoder_input.dtype).to(device)], -1)\n",
    "        decoder_outputs, _, _ = model.decoder(decoder_input, encoder_input, encoder_outputs)\n",
    "        projected = model.projection(decoder_outputs)\n",
    "        prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]\n",
    "\n",
    "        next_word = prob.data[-1]\n",
    "        next_symbol = next_word\n",
    "        if next_symbol == tgt_vocab[\"E\"]:\n",
    "            terminal = True\n",
    "    greedy_decoder_predict = decoder_input[:,1:]\n",
    "    return greedy_decoder_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 8, 4, 5, 6, 7, 0]) -> tensor([ 1,  2,  6,  7,  5, 10], device='cuda:0')\n",
      "['我', '有', '零', '个', '好', '朋', '友', 'P'] -> ['i', 'have', 'zero', 'girl', 'friend', '.']\n"
     ]
    }
   ],
   "source": [
    "s = [['我 有 零 个 好 朋 友 P', '', '']]\n",
    "enc_inputs, dec_inputs, dec_outputs = make_data(s)\n",
    "test_loader = Data.DataLoader(SentenceDataSet(enc_inputs, decoder_inputs, decoder_outputs), 2, True)\n",
    "enc_inputs, _, _ = next(iter(test_loader))\n",
    "\n",
    "for i in range(len(enc_inputs)):\n",
    "    greedy_dec_predict = greedy_decoder(model, enc_inputs[i].view(1, -1).to(device), start_symbol=tgt_vocab[\"S\"])\n",
    "    print(enc_inputs[i], '->', greedy_dec_predict.squeeze())\n",
    "    print([src_idx2word[t.item()] for t in enc_inputs[i]], '->', [tgt_idx2word[n.item()] for n in greedy_dec_predict.squeeze()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4a0e993b1d7c23b73f928b0a34114fba5233a538b73c46f7e69aa6023163c42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
